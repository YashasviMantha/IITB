{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from similarity.levenshtein import Levenshtein\n",
    "# v\n",
    "from similarity.normalized_levenshtein import NormalizedLevenshtein\n",
    "from similarity.weighted_levenshtein import WeightedLevenshtein\n",
    "from similarity.weighted_levenshtein import CharacterSubstitutionInterface\n",
    "from similarity.damerau import Damerau\n",
    "from similarity.optimal_string_alignment import OptimalStringAlignment\n",
    "from similarity.jarowinkler import JaroWinkler\n",
    "# v\n",
    "from similarity.longest_common_subsequence import LongestCommonSubsequence\n",
    "from similarity.metric_lcs import MetricLCS\n",
    "from similarity.ngram import NGram\n",
    "from similarity.qgram import QGram\n",
    "from similarity.cosine import Cosine\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "11.0\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "mword = 'बडाई'\n",
    "gword = 'शिष्टपण'\n",
    "mword_2 = 'बडाई'\n",
    "\n",
    "normalized_levenshtein = NormalizedLevenshtein()\n",
    "simVal_ls = normalized_levenshtein.distance(gword, mword)\n",
    "print(simVal_ls)\n",
    "\n",
    "lcs = LongestCommonSubsequence()\n",
    "simval_lcs = lcs.distance(mword, gword)\n",
    "print(simval_lcs)\n",
    "# =================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_func(source_data, target_data):\n",
    "    # striping \\n\n",
    "    for i in range(60000):\n",
    "        source_data[i] = source_data[i].strip('\\n')\n",
    "        target_data[i] = target_data[i].strip('\\n')\n",
    "\n",
    "        source_data[i] = source_data[i].split(';')\n",
    "        target_data[i] = target_data[i].split(';')\n",
    "\n",
    "        source_data[i][0] = int(source_data[i][0])\n",
    "        target_data[i][0] = int(target_data[i][0])\n",
    "\n",
    "    source_word_list = []\n",
    "    target_word_list = []\n",
    "    for i in range(60000):\n",
    "        source_word_list.append(source_data[i][1])\n",
    "        target_word_list.append(target_data[i][1])\n",
    "\n",
    "    for i in range(60000):\n",
    "        source_word_list[i] = source_word_list[i].strip()\n",
    "        target_word_list[i] = target_word_list[i].strip()\n",
    "\n",
    "        source_word_list[i] = source_word_list[i].split(',')\n",
    "        target_word_list[i] = target_word_list[i].split(',')\n",
    "\n",
    "    for i in range(60000):\n",
    "        for j in range(len(source_word_list[i])):\n",
    "            source_word_list[i][j] = source_word_list[i][j].strip()\n",
    "\n",
    "    for i in range(60000):\n",
    "        for j in range(len(target_word_list[i])):\n",
    "            target_word_list[i][j] = target_word_list[i][j].strip()\n",
    "\n",
    "    score_list_words = []\n",
    "    for i in range(60000):\n",
    "        n = 0\n",
    "        score = 0\n",
    "        for k in range(len(source_word_list[i])):\n",
    "            for l in range(len(target_word_list[i])):\n",
    "                if(source_word_list[i][k] == \"NULL\" or target_word_list[i][l] == \"NULL\" or source_word_list[i][k] == \"null\" or target_word_list[i][l] == \"null\"):\n",
    "                    n = 1\n",
    "                    continue\n",
    "                n = n + 1\n",
    "                score = score + normalized_levenshtein.distance(source_word_list[i][k], target_word_list[i][l])\n",
    "        score = score / n\n",
    "        score_list_words.append(score)\n",
    "\n",
    "#     word_sim = 0\n",
    "#     for i in score_list:\n",
    "#         word_sim = word_sim + i\n",
    "#     word_sim = word_sim / 60000\n",
    "\n",
    "# Context---------------------------------------------------------------------------------------\n",
    "\n",
    "    source_context_list = []\n",
    "    target_context_list = []\n",
    "    for i in range(60000):\n",
    "        source_context_list.append(source_data[i][2])\n",
    "        target_context_list.append(target_data[i][2])\n",
    "\n",
    "    for i in range(60000):\n",
    "        source_context_list[i] = source_context_list[i].strip()\n",
    "        target_context_list[i] = target_context_list[i].strip()\n",
    "\n",
    "        source_context_list[i] = source_context_list[i].split()\n",
    "        target_context_list[i] = target_context_list[i].split()\n",
    "\n",
    "\n",
    "    for i in range(60000):\n",
    "        for j in range(len(source_context_list[i])):\n",
    "            source_context_list[i][j] = source_context_list[i][j].strip()\n",
    "\n",
    "    for i in range(60000):\n",
    "        for j in range(len(target_context_list[i])):\n",
    "            target_context_list[i][j] = target_context_list[i][j].strip()\n",
    "\n",
    "    score_list_context = []\n",
    "    for i in range(60000):\n",
    "        score = 0\n",
    "        n = 0\n",
    "        for k in range(len(source_context_list[i])):\n",
    "            for l in range(len(target_context_list[i])):\n",
    "                n = n + 1\n",
    "                score = score + normalized_levenshtein.distance(source_context_list[i][k], target_context_list[i][l])\n",
    "        score = score / n\n",
    "        score_list_context.append(score)\n",
    "#     context_sim = 0\n",
    "#     for i in score_list_context:\n",
    "#         context_sim = context_sim + i\n",
    "#     context_sim = context_sim / 60000\n",
    "    return score_list_words, score_list_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-a9a047030f5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtarget_data_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mscore_list_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_list_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_data_l\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_data_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwritefile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-264801c24383>\u001b[0m in \u001b[0;36msim_func\u001b[0;34m(source_data, target_data)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_context_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnormalized_levenshtein\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_context_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_context_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mscore_list_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/similarity/normalized_levenshtein.py\u001b[0m in \u001b[0;36msimilarity\u001b[0;34m(self, s0, s1)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/similarity/normalized_levenshtein.py\u001b[0m in \u001b[0;36mdistance\u001b[0;34m(self, s0, s1)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mm_len\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevenshtein\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/similarity/levenshtein.py\u001b[0m in \u001b[0;36mdistance\u001b[0;34m(self, s0, s1)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0ms0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mv1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mv0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_list_full = os.listdir('../Cleaned_data/')\n",
    "file_list = []\n",
    "for i in file_list_full:\n",
    "    if(i.endswith('.csv')):\n",
    "        file_list.append(i)\n",
    "\n",
    "sim_file = open('sim_file.txt','w+')\n",
    "for i in range(len(file_list)):\n",
    "    for j in range(len(file_list)):\n",
    "        if(file_list[i]!=file_list[j]):\n",
    "            source_file = open('../Cleaned_data/'+file_list[i],'r',encoding='utf8')\n",
    "            target_file = open('../Cleaned_data/'+file_list[j],'r',encoding='utf8')\n",
    "            source_data_l = source_file.readlines()\n",
    "            target_data_l = target_file.readlines()\n",
    "            score_list_words, score_list_context = sim_func(source_data_l,target_data_l)\n",
    "            sname = file_list[i].replace(\".csv\",\"\")\n",
    "            tname = file_list[j].replace(\".csv\",\"\")\n",
    "            fname = sname+\"_\"+tname+\".txt\"\n",
    "            with open(fname, 'w+') as writefile:\n",
    "                print(\"Processing: \"+fname)\n",
    "                for k in tqdm(range(60000)):\n",
    "                    writefile.write(str(k)+\";\"+str(score_list_words[k])+\";\"+str(score_list_context[k])+\"\\n\")\n",
    "        \n",
    "#         sim_string =str(file_list[i]) + ' ' + str(file_list[j]) + ' ' + str(word_score) + ' ' + str(context_score) + '\\n' \n",
    "#         sim_file.writelines(sim_string)\n",
    "#         print(sim_string)\n",
    "#     print(\"processed \", file_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.729397946389454"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60000, 'NULL', 'NULLNULL ']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te.csv\n",
      "gu.csv\n",
      "as.csv\n",
      "kn.csv\n",
      "ml.csv\n",
      "sa.csv\n",
      "or.csv\n",
      "ta.csv\n",
      "bn.csv\n",
      "ko.csv\n",
      "ne.csv\n",
      "pa.csv\n",
      "mr.csv\n",
      "hi.csv\n"
     ]
    }
   ],
   "source": [
    "file_list_full = os.listdir('../Cleaned_data/')\n",
    "for i in file_list_full:\n",
    "    if(i.endswith('.csv')):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
